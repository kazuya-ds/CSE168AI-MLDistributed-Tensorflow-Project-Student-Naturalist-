{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff1ae4c-c33e-4292-bbf2-1230896b03b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca6593-ece3-4c79-bbf8-ac98f68e8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: https://github.com/AkhilPenta/Steel-Defect-Detection/blob/8bf2a50f8a73361255ea7972ea81dffca49b1f55/UNET.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651d01d-be9e-4095-9a3f-9762028ede2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow Unet import\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Dropout, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Concatenate, Add\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac9fb12-d2a4-4d18-ba5b-b1c766badff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a280a-13e9-4fdf-9503-21aa4c89badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect with cse120 google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70be74f2-6478-4024-aa09-bf699bd908fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/content/drive/MyDrive/cs2/' #replace with data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2db7f2-d99e-4cd5-a596-a3caa4c36cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(path+'data/full_data.csv').fillna('')\n",
    "full_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbcccfe-294a-4fc5-85e2-5c7990c818c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split traiing\n",
    "#splitting the data into train & cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, validtn_data = train_test_split(full_data, test_size=0.15, random_state=42)\n",
    "print(train_data.shape)\n",
    "print(validtn_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011b21d7-bed8-4a93-a641-a2516f454c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the train and validation data in csv files for future use\n",
    "train_data.to_csv(path + \"data/train_data.csv\", index=False)\n",
    "validtn_data.to_csv(path + \"data/validtn_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e40be-da79-4c81-8887-723d0856c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading train and validation data\n",
    "train_data = pd.read_csv(path + \"data/train_data.csv\").fillna('')\n",
    "validtn_data = pd.read_csv(path + \"data/validtn_data.csv\").fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384557ba-74a3-495e-aa79-7c43118829b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2 Data Generator Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07678b45-e25c-4123-b7ee-a3d2aa3a3351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing custom data generator\n",
    "#https://towardsdatascience.com/implementing-custom-data-generators-in-keras-de56f013581c\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, batch_size=32, num_classes=None, shuffle=True, preprocess=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.df = dataframe\n",
    "        self.indices = self.df.index.tolist()\n",
    "        self.preprocess = preprocess\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // (self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in index]\n",
    "        \n",
    "        X, y = self.__get_data(batch)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        train_datagen = ImageDataGenerator()\n",
    "        param = {'flip_horizontal':True, 'samplewise_std_normalization' : True,\n",
    "                 'width_shift_range':0.1, 'height_shift_range':0.1,}\n",
    "        X = np.empty((self.batch_size,256,1600,3),dtype=np.float32) # image place-holders\n",
    "        Y = np.empty((self.batch_size,256,1600,4),dtype=np.float32)# 4 masks place-holders\n",
    "              \n",
    "        for i, id in enumerate(batch):\n",
    "          img = Image.open(path+'data/train_images/' + str(self.df['ImageId'].loc[id]))\n",
    "          X[i,] = train_datagen.apply_transform(x = img, transform_parameters = param)#input image\n",
    "          for j in range(4): #looping for each class\n",
    "                mask = rle2mask(self.df['rle_'+str(j+1)].loc[id])\n",
    "                Y[i,:,:,j] = train_datagen.apply_transform(x = mask, transform_parameters = param)#mask for each class\n",
    "                \n",
    "        # preprocess input\n",
    "        if self.preprocess!=None: X = self.preprocess(X)\n",
    "\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c8bd3-d3e6-42ee-b87c-b51d5519b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.3 Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b1804-3507-4410-997f-42f1ea66d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/titericz/building-and-visualizing-masks\n",
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "\n",
    "#defining function for converting EncodedPixels(rle: run length encoding) to mask\n",
    "def rle2mask(rle_string, img_shape=(256,1600)):\n",
    "    '''\n",
    "    input: EncodedPixels (run-length-encoded) string & image shape:-(width,height)\n",
    "    output: mask in numpy.ndarray format with shape (256,1600)\n",
    "    '''\n",
    "    rle_array = np.array([int(s)for s in rle_string.split()])\n",
    "    starts_array = rle_array[::2]-1\n",
    "    lengths_array = rle_array[1::2]\n",
    "    mask_array = np.zeros(img_shape[0]*img_shape[1],dtype=np.uint8)\n",
    "    #print(starts_array,lengths_array)\n",
    "    for i in range(len(starts_array)):\n",
    "        mask_array[starts_array[i]:starts_array[i]+lengths_array[i]] = 1\n",
    "    #order='F' because encoded pixels are numbered from top to bottom, then left to right\n",
    "    return mask_array.reshape(img_shape, order = 'F')\n",
    "\n",
    "#defining function for converting given mask to EncodedPixels(rle: run length encoding)\n",
    "def mask2rle(mask_array):\n",
    "    '''\n",
    "    input: mask in numpy.ndarray format\n",
    "    output: EncodedPixels (run-length-encoded) string\n",
    "    '''\n",
    "    mask_array = mask_array.T.flatten()\n",
    "    mask_array = np.concatenate([[0], mask_array, [0]])\n",
    "    rle_array = np.where(mask_array[1:]!=mask_array[:-1])[0]+1\n",
    "    rle_array[1::2] -= rle_array[::2]\n",
    "    rle_string = ' '.join(map(str,rle_array))\n",
    "    return rle_string\n",
    "\n",
    "#defining function for calculation of metric dice coefficient\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.math.reduce_sum(y_true_f * y_pred_f)\n",
    "    smoothing_const = 1e-9\n",
    "    return (2. * intersection + smoothing_const) / (tf.math.reduce_sum(y_true_f) + tf.math.reduce_sum(y_pred_f) + smoothing_const)\n",
    "\n",
    "#defining function for calculation of dice coefficient\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    return (1-dice_coefficient(y_true, y_pred))\n",
    "\n",
    "#defining function for calculation of loss function: binary cross entropy + dice loss\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    return binary_crossentropy(y_true, y_pred) + (1-dice_coefficient(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f00755-d0ed-4cd1-a805-7ef9b5902372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.4 Defining Unet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5698db-34ba-4677-99a2-45337eaefc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining Unet architecture\n",
    "# https://arxiv.org/abs/1505.04597\n",
    "# https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47\n",
    "# https://github.com/hlamba28/UNET-TGS\n",
    "\n",
    "def conv2D_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True ):\n",
    "    \"\"\"function to pass Input_tensor through 2- Conv2D layers configured as per the input parameters\"\"\"\n",
    "    # first Conv2D layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "            kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    # second Conv2D layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "            kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def Unet_Model(input_image, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "    # Encoder (Contraction Path)\n",
    "    E1 = conv2D_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(E1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "\n",
    "    E2 = conv2D_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(E2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    E3 = conv2D_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(E3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    E4 = conv2D_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(E4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "\n",
    "    E5 = conv2D_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    # Decoder (Expansive Path)\n",
    "    D6 = Conv2DTranspose(n_filters * 8, kernel_size = (3, 3), strides = (2, 2), padding = 'same')(E5)\n",
    "    D6 = Concatenate()([D6, E4])\n",
    "    D6 = Dropout(dropout)(D6)\n",
    "    E6 = conv2D_block(D6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    D7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(E6)\n",
    "    D7 = Concatenate()([D7, E3])\n",
    "    D7 = Dropout(dropout)(D7)\n",
    "    E7 = conv2D_block(D7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    D8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(E7)\n",
    "    D8 = Concatenate()([D8, E2])\n",
    "    D8 = Dropout(dropout)(D8)\n",
    "    E8 = conv2D_block(D8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    D9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(E8)\n",
    "    D9 = Concatenate()([D9, E1])\n",
    "    D9 = Dropout(dropout)(D9)\n",
    "    E9 = conv2D_block(D9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    outputs = Conv2D(4, (1, 1), activation='sigmoid')(E9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa0121-f7c3-4b14-b889-c6be51afaddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing the model layers,Total params: 295,972\n",
    "# Trainable params: 295,236\n",
    "# Non-trainable params: 736\n",
    "#configuring input tensor\n",
    "input_img = Input((256, 1600, 3), name='img')\n",
    "\n",
    "model = Unet_Model(input_img, n_filters=8, dropout=0.2, batchnorm=True)\n",
    "model.compile(optimizer=Adam(), loss=bce_dice_loss, metrics=[dice_coefficient])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c3ed15-fba9-4ddc-9a59-88287e5bbfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading train & validation data using DataGenerator class defined\n",
    "train_batches = DataGenerator(train_data,shuffle=True)\n",
    "validtn_batches = DataGenerator(validtn_data,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889bddb-bef2-4017-9b49-340843f11016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get checkpoints and time\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import datetime, os\n",
    "\n",
    "# #tensorboard for visualizing loss & metric summary \n",
    "# logdir = path+\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = TensorBoard(logdir)\n",
    "\n",
    "#defining ModelCheckpoint to make a checkpoint when validation dice coefficient improves\n",
    "checkpoints = ModelCheckpoint(path+'unet.h5', \\\n",
    "                              monitor='val_dice_coefficient', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "#adding ModelCheckpoint & TensorBoard to callback functions list\n",
    "callbacks_list = [checkpoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672c564-a343-451e-9f40-4d27e1075db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156276ca-9e32-4e12-812b-a62e9e3c9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "history = model.fit(train_batches,validation_data=validtn_batches, epochs = 60, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e51321-d1e5-4d40-8d1a-270370abc195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40146c-3ab1-43fd-becc-9350edb724fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing history for dice_coefficient\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(history.history['dice_coefficient'])\n",
    "plt.plot(history.history['val_dice_coefficient'])\n",
    "plt.title('model dice_coefficient')\n",
    "plt.ylabel('dice_coefficient')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# Visualizing history for loss\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('bce_dice_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c20c55-b804-40d0-8cfa-45756ece4d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving epoches history for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25276d-2f43-445c-81ba-7eb13f323f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving history data for first 60 epochs in csv file\n",
    "history1 = pd.DataFrame(history.history)\n",
    "history1.to_csv(path + \"data/history1-unet.csv\", index=True)\n",
    "# saving model(weights upto 60 epochs)\n",
    "model.save(path+'unet-60epochs.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210892c2-1c21-4eb2-8093-a02a3bd7009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing and Visualizing Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b7f18-1cb8-4734-99b1-c771785b3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating model(best weights) with the validation batch\n",
    "model.load_weights(path + 'unet.h5')\n",
    "loss, dc= model.evaluate(validtn_batches,verbose=1)\n",
    "print('loss:',loss, 'dice_coefficient:',dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aefe65-b047-4a71-9940-b72ec05b4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Ground Truth and Predicted Mask Images for given set of images#defining function to display GroundTruth & Predicted mask images for a given imageId\n",
    "def visualize_model_prediction(img_id):\n",
    "    fig, axs = plt.subplots(4, 3, figsize=(16,8))\n",
    "    img_obj = cv2.imread(path+'data/train_images/'+ img_id)\n",
    "    masks_actual = full_data[full_data['ImageId'] == img_id]\n",
    "    x = np.empty((1,256,1600,3),dtype=np.float32) # image place-holders\n",
    "    x[0,] = Image.open(path+'data/train_images/' + img_id)\n",
    "    masks_predicted = model.predict(x)\n",
    "    for i in range(4):\n",
    "        axs[i,0].imshow(img_obj)\n",
    "        axs[i,0].set_title(img_id)\n",
    "        axs[i,1].imshow(rle2mask(masks_actual['rle_'+str(i+1)].iloc[0]))\n",
    "        axs[i,1].set_title(\"Actual mask for Class '{}'\".format(i+1) )\n",
    "        axs[i,2].imshow(masks_predicted[0,:,:,i])\n",
    "        axs[i,2].set_title(\"Predicted mask for Class '{}'\".format(i+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd452d4c-597e-4cb1-8b3d-f3b367a666b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model_prediction('0002cc93b.jpg') #replace with one jpg from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562817e0-492c-4076-89a1-c6094a2ca79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model_prediction('4d38c353e.jpg') #show another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942b7c7-b371-4b1d-885b-3e26952dccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.7 Preparing Data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c26ce9-a4f1-4b83-a1ce-43524cfeb82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,dataframe, list_idcs, batch_size=32, ):\n",
    "        self.batch_size = batch_size\n",
    "        self.df = dataframe\n",
    "        self.list_idcs = list_idcs\n",
    "        self.indices = self.df.index.tolist()\n",
    "        self.rem = len(self.list_idcs) % (self.batch_size)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "         return len(self.list_idcs) // (self.batch_size)\n",
    "#         if (self.rem) == 0:\n",
    "#             return len(self.list_idcs) // (self.batch_size)\n",
    "#         else:\n",
    "#             return (len(self.list_idcs) // (self.batch_size) )+1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "#         if ((index + 1) * self.batch_size) < len(self.list_idcs):\n",
    "#             index = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "#         else:\n",
    "#             index = self.indices[index * self.batch_size: (index * self.batch_size)+ self.rem]\n",
    "        batch = [self.list_idcs[k] for k in index]\n",
    "        \n",
    "        X = self.__get_data(batch)\n",
    "         \n",
    "        return X\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.indices))\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        X = np.empty((self.batch_size,256,1600,3),dtype=np.float32) # image place-holders\n",
    "              \n",
    "        for i, id in enumerate(batch):\n",
    "            img = Image.open(path + 'data/test_images/' + str(self.df['ImageId'].loc[id]))\n",
    "            X[i,] = img#input image\n",
    "\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71797882-114c-4293-a111-6d778a746af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get id of test imgs\n",
    "\n",
    "test_img_IDs = list(os.listdir(path + 'data/test_images/'))\n",
    "test_imgsIds_df = pd.DataFrame({'ImageId': test_img_IDs})\n",
    "print(len(test_imgsIds_df))\n",
    "test_imgsIds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac45ad-24cb-4727-b689-c41d5f949499",
   "metadata": {},
   "outputs": [],
   "source": [
    "SubmissionDf = pd.DataFrame(columns = ['ImageId','EncodedPixels','ClassId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c45714-4825-4d90-bf45-cece8099900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(test_imgsIds_df),320):\n",
    "    batch_idcs =  list(range(i, min(test_imgsIds_df.shape[0], i + 320)))#.iloc[batch_idcs]\n",
    "    if len(batch_idcs)== 320:        \n",
    "        test_subbatch = PredictDataGenerator(dataframe = test_imgsIds_df,\n",
    "                                             list_idcs = batch_idcs)\n",
    "    else:\n",
    "        test_subbatch = PredictDataGenerator(dataframe = test_imgsIds_df,\n",
    "                                             list_idcs = batch_idcs,\n",
    "                                             batch_size= len(batch_idcs))\n",
    "    #print(len(test_subbatch))\n",
    "    subbatch_pred_masks = model.predict(test_subbatch)\n",
    "    #print(len(subbatch_pred_masks))\n",
    "    #break\n",
    "    for j, idx in tqdm(enumerate(batch_idcs)):\n",
    "        filename = test_imgsIds_df['ImageId'].iloc[idx]\n",
    "        rle1 = mask2rle(subbatch_pred_masks[j,:,:,0].round().astype(int))\n",
    "        rle2 = mask2rle(subbatch_pred_masks[j,:,:,1].round().astype(int))\n",
    "        rle3 = mask2rle(subbatch_pred_masks[j,:,:,2].round().astype(int))\n",
    "        rle4 = mask2rle(subbatch_pred_masks[j,:,:,3].round().astype(int))\n",
    "        df = pd.DataFrame({'ImageId':[filename]*4,\n",
    "                      'EncodedPixels': [rle1,rle2,rle3,rle4],\n",
    "                      'ClassId':['1', '2', '3', '4']})\n",
    "        SubmissionDf = SubmissionDf.append(df,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f8965f-3e9b-4829-8fb8-bfe2ca80aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SubmissionDf.sort_values(by=['ImageId', 'ClassId'], inplace=True)\n",
    "SubmissionDf['ImageId_ClassId'] = SubmissionDf['ImageId'] + '_' + SubmissionDf['ClassId']\n",
    "print(SubmissionDf.shape)\n",
    "SubmissionDf.head(10)SubmissionDf.to_csv(path+'submission-unet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b3b70-e027-4011-b122-c799a17088ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "SubmissionDf.to_csv(path+'submission-unet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04bc1e-9bd3-4b4f-8c1f-3443e16e1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaggle Score, replace with check annotated validation set with modle predictions for training and check if over fit\n",
    "from IPython.display import Image\n",
    "Image(filename='unet.JPG') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
